# Environment Configuration

# LLM Provider (openai, anthropic, openrouter, ollama, lmstudio)
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=openai/gpt-4o-mini

# Anthropic Configuration
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# OpenRouter Configuration
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
# OPENROUTER_SITE_URL=https://your-site.com  # Optional: for rankings
# OPENROUTER_APP_NAME=MTG-Commander-AI        # Optional: for rankings

# Ollama Configuration (for local models)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1:8b

# LM Studio Configuration (for local models with OpenAI-compatible API)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LMSTUDIO_MODEL=local-model  # Use the model identifier from LM Studio

# LLM Generation Settings
# LLM_MAX_TOKENS: Maximum tokens for model response (default: 4000)
# - Standard models (GPT-4, Claude): 2000-4000 is sufficient
# - Reasoning models (DeepSeek-R1, Qwen3-thinking, o1/o3): 4000-8000 recommended
# - Set higher if you see "Finish Reason: length" truncation in logs
# LLM_MAX_TOKENS=4000

# Game Configuration
# Note: Use command-line flags instead (e.g., python run.py --max-turns=20 --verbose)
# MAX_TURNS=10  # Controlled via --max-turns flag
# VERBOSE=true  # Controlled via --verbose flag

# Vector Database (optional, for future use)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=

# Logging
LOG_LEVEL=INFO
